{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFKrGgzBm3Y7PGL4x7JT0t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akkkiii08/Deep-Learning/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Recurrent Neural Network**\n",
        "\n",
        "We will explore the concept of the Recurrent Neural Network.\n",
        "\n",
        "Recurrent Neural Networks (RNNs) are a type of neural network designed for processing sequences of data. Unlike traditional neural networks, which assume that inputs are independent of each other, RNNs consider the order and dependencies between elements in a sequence. This makes them particularly useful for tasks like language modeling, speech recognition, and time series prediction.\n",
        "\n",
        "In an RNN, information cycles through a loop, allowing it to maintain a memory of previous inputs and make decisions based on the context of the entire sequence. However, RNNs can struggle with long-term dependencies, which has led to the development of more advanced architectures like LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Unit) networks that better handle these challenges.\n",
        "\n",
        "We will take an program which will help to understand how the RNNs works.This program will cover the basic structure and steps involved in building and training an RNN."
      ],
      "metadata": {
        "id": "TE2RIL6l_ejr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtfOHb5rXhZV",
        "outputId": "897932b8-d29b-4493-fad2-4ebdde94ee0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "YFYrb4xQXwPN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text\n",
        "text = \"hello world\"\n",
        "\n",
        "# Create a mapping from unique characters to indices\n",
        "vocab = sorted(set(text))\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "# Convert text to integers\n",
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "\n",
        "# Show the first characters and their indices\n",
        "print('{')\n",
        "for char,_ in zip(char2idx, range(len(char2idx))):\n",
        "    print(f'  {repr(char)}: {char2idx[char]}')\n",
        "print('}\\n')\n",
        "print(f'{text} ----> {text_as_int}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Py6vCptX1xt",
        "outputId": "e994c205-f97e-4b33-bd86-4600da7f6f2d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  ' ': 0\n",
            "  'd': 1\n",
            "  'e': 2\n",
            "  'h': 3\n",
            "  'l': 4\n",
            "  'o': 5\n",
            "  'r': 6\n",
            "  'w': 7\n",
            "}\n",
            "\n",
            "hello world ----> [3 2 4 4 5 0 7 5 6 4 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of each sequence\n",
        "seq_length = 4\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "sequences = []\n",
        "for i in range(examples_per_epoch):\n",
        "    start_index = i * (seq_length + 1)\n",
        "    end_index = start_index + seq_length + 1\n",
        "    seq = text_as_int[start_index:end_index]\n",
        "    sequences.append(seq)\n",
        "\n",
        "# Split sequences into input and target\n",
        "inputs = np.array([seq[:-1] for seq in sequences])\n",
        "targets = np.array([seq[1:] for seq in sequences])\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "inputs = torch.tensor(inputs, dtype=torch.long)\n",
        "targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "# Print the first example\n",
        "print(f'Input data: {inputs[0]}, Target data: {targets[0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZVmCztbX7c6",
        "outputId": "8ba603f3-6148-4e7d-9b3e-d9d4295defd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data: tensor([3, 2, 4, 4]), Target data: tensor([2, 4, 4, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Hyperparameters\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 8\n",
        "hidden_dim = 16\n",
        "output_dim = vocab_size\n",
        "\n",
        "# Instantiate the model\n",
        "model = RNN(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssEvtfrBYC6V",
        "outputId": "8550c7f1-9bd2-4774-bade-2f4ad8f07c45"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(\n",
            "  (embedding): Embedding(8, 8)\n",
            "  (rnn): RNN(8, 16, batch_first=True)\n",
            "  (fc): Linear(in_features=16, out_features=8, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "hhxnqnIwYNlV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of epochs\n",
        "EPOCHS = 100\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for i in range(len(inputs)):\n",
        "        input_seq = inputs[i].unsqueeze(0)  # Add batch dimension\n",
        "        target_seq = targets[i]\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(input_seq)\n",
        "        loss = criterion(output.squeeze(), target_seq)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimize\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {loss.item()}')\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7B9Zu02YRQe",
        "outputId": "4fdf9da5-3a27-4c77-9f43-bccc7f30ce21"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 2.225950241088867\n",
            "Epoch 11/100, Loss: 1.9889894723892212\n",
            "Epoch 21/100, Loss: 1.7738288640975952\n",
            "Epoch 31/100, Loss: 1.5753997564315796\n",
            "Epoch 41/100, Loss: 1.3907095193862915\n",
            "Epoch 51/100, Loss: 1.210460901260376\n",
            "Epoch 61/100, Loss: 1.03239905834198\n",
            "Epoch 71/100, Loss: 0.8655322790145874\n",
            "Epoch 81/100, Loss: 0.7178366184234619\n",
            "Epoch 91/100, Loss: 0.5922159552574158\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string, num_generate=10):\n",
        "    input_eval = torch.tensor([char2idx[s] for s in start_string], dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "    text_generated = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_generate):\n",
        "            output = model(input_eval)\n",
        "            predicted_id = torch.argmax(output[0, -1, :]).item()\n",
        "            input_eval = torch.cat((input_eval, torch.tensor([[predicted_id]], dtype=torch.long)), dim=1)\n",
        "            text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return start_string + ''.join(text_generated)\n",
        "\n",
        "# Generate text\n",
        "print(generate_text(model, start_string=\"helo\", num_generate=10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArWz5BeMYdoZ",
        "outputId": "87af0e02-596e-4b79-d17a-07e711e7f675"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heloollorlorlo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion:\n",
        "In this simple project, following has been done:\n",
        "\n",
        "Prepared a small text dataset.\n",
        "Built an RNN model using PyTorch.\n",
        "Trained the model on the text data.\n",
        "Generated new text based on the learned patterns."
      ],
      "metadata": {
        "id": "F5L_i2tWiHTc"
      }
    }
  ]
}